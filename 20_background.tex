
% Jonathan:
% https://www.aclweb.org/anthology/P12-1013.pdf

% https://www.aclweb.org/anthology/P11-1062.pdf

% https://www.aclweb.org/anthology/P10-1124.pdf


% Mohammad Javad Hosseini:
% https://www.aclweb.org/anthology/P19-1468.pdf

% https://www.mitpressjournals.org/doi/pdfplus/10.1162/tacl_a_00250

% inference
% https://arxiv.org/pdf/1909.07521.pdf
% https://arxiv.org/pdf/2002.05867.pdf
% https://arxiv.org/pdf/2006.06609.pdf
% https://arxiv.org/pdf/2007.00655.pdf

\section{Background}
\label{sec:background}

There has been significant interest in analyzing the capabilities of PLMs \cite{rogers2020primer}, including linguistic tasks \cite{yoav-syntax,hewitt2019structural,tenney2019bert,amnesic_probing}, commonsense capabilities \cite{forbes2019neural, da2019cracking,zhang2020language} and ability to reason \cite{talmor2019olmpics, kassner-etal-2020-pretrained}. However, there has been considerably less research attention devoted to analyzing if models behave \emph{consistently} on these abilities. That is, to what extent do such probes uncover generalizable capabilities of a model, and how indicative they are of 
factual knowledge. 
% a coherent set of beliefs in the model \sr{not so clear}\yg{i dislike "beliefs"}. 
Some initial work in this area has shown that models tend to generate facts and their negation, a type of inconsistent behavior \cite{Ettinger_2020,kassner-schutze-2020-negated}. \newcite{ravichander-etal-2020-systematicity} proposed consistency probes---paired probes to evaluate the ability of PLM to behave in a coherent manner. Our work is broader in scope, examining the behavior of PLMs across a range of factual knowledge types, and investigating how models can be made to behave more consistently. 

Consistency has also been highlighted as a desirable property in automatically constructed KBs and downstream NLP tasks, which we describe below:

\paragraph{Consistency in Knowledge Bases}

Consistency has been studied under theoretical frameworks in the contexts of the satisfiability problem and KBs constructions, and efficient algorithms that detect inconsistencies in KBs have been proposed \cite{hansen2000probabilistic,andersen2001easy}.
Other works, aim to quantify the degree to which KBs are inconsistent and detect inconsistent statements \cite{Thimm:2009d,muino2011measuring,Thimm:2013}.



\paragraph{Consistency in Question Answering}
The consistency of models was studied in the Q\&A domain as well. \citet{ribeiro-etal-2019-red} studied the consistency capabilities of several models, in two Q\&A tasks: Visual Question Answering \cite{vqa} and Reading Comprehension \cite{squad}. They automatically generate questions, allowing them to test the consistency of Q\&A models.
Their findings suggest that most models are not consistent in their predictions. In addition, they use data augmentation to create more robust models.
\citet{alberti2019synthetic} proposed to generate new questions conditioned on the context and answer from a labeled dataset, and by filtering answers that do not provide a consistent result with the original answer. The authors show that pretraining on this synthetic data improves the results on Q\&A datasets.
\citet{consistent-qa} proposed to use data augmentation that complements questions with symmetricity and transitivity, as well as a regularizing loss that penalizes inconsistent predictions.

\paragraph{Consistency in Other Domains}
Consistency was also studied in other domains. For example, \citet{du2019consistent} improves predictions consistency in procedural text over similar descriptions. \citet{ribeiro-etal-2020-beyond} uses consistency for more robust evaluation. \citet{li-etal-2019-logic} measure and mitigate inconsistency in natural language inference.

%\ar{We should add work examining consistency in PLMs - i.e negated lama, systematicity of probing cwr, }