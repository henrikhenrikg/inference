% \section{Consistency Probing of Knowledge}
\section{Probing for Consistency}
\label{sec:framework}

In this section, we formally detail our proposed framework that allows probing for consistency of PLMs.



\paragraph{The Framework}
We begin with a set of $m$ KB triplets $D = \{D_1, D_2, \dots, D_m\}$, where each $D_i$ contains factual statements that express a specific relation $R(D_i)$, such as ``aired on''. Each $D_i$ is composed of $n$ examples $D_i = \{d_1^i, d_2^i, \dots, d_n^i\}$, where each $d_j^i = <s_j^i, o_j^i, p_j^i>$ is a triplet of a subject, an object, and a unique pattern that expresses the relation $R(D_i)$, respectively. For instance, if $R(D_1)=\text{``originally aired on"}$ then a triplet in $D_1$ can be $< \text{\textit{Homeland}}, \text{\textit{Showtime}}, \text{\textit{\subj{} was originally aired on \obj{}}}>$.



Given some relation $R(D_i)$, and two factual statements associated with this relation $d_j^i$ and $d_k^i$ (such as ``Homeland was originally aired on Showtime'' and ``Showtime released Homeland''), our goal is to test whether the model consistently predicts $d_k^i$ and $d_j^i$, given that we know that $p_j^i$ and $p_k^i$ are paraphrases.
To this end, we mask the objects $o_j^i$ and $o_k^i$ and ask the model to predict them: ``Homeland was originally aired on [MASK]'' and ``[MASK] released Homeland''.
Then, expecting a consistent model to predict the same answer.
Notice that the consistency measure does not require the answers to be factually correct, an important property for KBs, which is measured with a different metric.
% If the model predicts the correct $o_j^i$ as the most probable completion, we take that as evidence for the storing of the factual knowledge $d_j^i$ in the model. 
% In this case, a model that can perform adequate inference over the syntactic and lexical alternations between $p_j^i$ and $p_k^i$ is expected to also correctly predict the object from the alternative patterns $p_k^i$.

\paragraph{Candidate Sets}
Ideally, we would treat the top-1 prediction that the PLM produces in order to compare between paraphrases. However, since these models were not trained for the purpose of serving as KBs, but as LMs, words outside of the inspected entities are often possible (e.g. the object in ``\subj{} was originally aired on \obj{}'' can also be replaced with `tv', to make a proper English sentence).
Therefore, we restrict the vocabulary produced by the PLMs to a candidate set, that is the set of possible gold objects for each relation, as was also suggested in previous work \cite{Xiong2020Pretrained, nora}.

Note that this procedure is a relaxation of the general problem, especially in the context of KBs, however, low consistency results in this setup are even more alarming.