% \section{Consistency Probing of Knowledge}
\section{Probing PLMs for Consistency}
\label{sec:probe}

In this section, we formally detail our definition for consistency as well as the proposed framework that allows probing for consistency of PLMs.

\subsection{Consistency}
We define consistency as follows: two cloze-phrases that are \textit{quasi-paraphrases} should result in the same prediction.
%We use the term consistency in the sense that two cloze-phrases that are \textit{quasi-paraphrases} should result in the same prediction. 
\textit{Quasi-paraphrases} is a concept introduced by \citet{what_is_paraphrase} that allow using a more fuzzy notion of paraphrases, which does not rely on the strict, logical definition of paraphrases, and allows to operationalize concrete use of paraphrases. This definition is in the spirit of the RTE definition \cite{dagan-rte}, which also allows a more flexible definition for Entailment.\yg{consider moving the quasi-paraphrase definition and discussion to footnote, esp if need space}
In the context of PLM knowledge consistency, if two cloze-phrases\yg{we didn't define cloze-phrases yet. do they include a relation tuple?} of some relation (e.g. \textit{originally-aired-on}) are quasi-paraphrases, masked language models should predict the same entity for the masked item. 
% \sr{I changed the wording here. Is it still what you meant? a natural question now is ``why objects".}
% \yg{can it be "masked item"? or is it really a syntactic object?}
In the rest of the paper, we use the terms \textit{paraphrase} and \textit{quasi-paraphrase} interchangeably.

 

We note that this definition does not take into account the type (e.g. one-to-one, or many-to-many relations) of the relation. %\yg{what relation? we didn't say relation in this secction until now.} 
For instance, some relations are defined as \textit{many-to-many}, and as such, more than a single item can be factually correct, even for quasi-paraphrases. However, we still expect that the order will remain, and thus even if the alternative answer is factually correct, we still consider cases with different answers as a non-consistent result.

\subsection{The Framework}
\label{sec:framework}
Let
$D = \{D_1, D_2,
\dots, D_m\}$
be a set of sets of KB triples,
where each $D_i$ contains factual statements
that express a specific relation $R_i$, such as ``aired
on''. Each $D_i$ is composed of $n$ examples $D_i = \{d_1^i,
d_2^i, \dots, d_n^i\}$, where each $d_j^i = <s_j^i,o_j^i>$ is a tuple of a subject, and an object from the relation $R_i$. 
For instance, if $R_1=\text{``originally
  aired on"}$ then a tuple in $D_1$ can be $<\text{\textit{Homeland}}, \text{\textit{Showtime}}>$. Moreover, every relation $D_i$ \am{I thought $R_i$ is the relation} is associated with a set of cloze-patterns $P_i$ that are \textit{quasi-paraphrases} and express the same relation. For example, $P_1=\{p_1^1, p_2^1, \dots, p_n^1\}$ contain the patterns ``\subj{} was originally aired on \obj{}'' and ``\subj{} was premiered on \obj{}''.
\nk{I think we should have someone who is not familiar with our setup check this passage. I am not sure if everyone will understand it}
\yg{I agree, hard to follow. I propose to possible solutions: (1) start bottom-up rather than top-down: this is a pattern, here is a group of patterns, now we collect them into a set... (2) visualize it in a figure (instead of the text).}
\am{while I'm familiar with this work, reading this paragraph for the first time I can understand the definitions. I agree with Yoav that a visualization can help though}

Given some relation $R_i$, a subject-object tuple $d_j^i \in D_i$ (e.g. `Homeland', `Showtime') and two paraphrases $p_k^i, p_l^i \in P_i$ associated with this relation (such as ``\subj{} was originally aired on \obj{}'' and ``\subj{} premiered on \obj{}''), our goal is to test whether the model, consistently predicts the same object after filling the subject entity. To this end, we populate each of the subjects and a mask token to the pattern $p_k^i(s_j^i,mask)$, $p_l^i(s_j^i,mask)$
% we mask the objects $o_j^i$ 
and ask the model to predict them: ``Homeland was originally aired on [MASK]'' and ``Homeland was premiered on [MASK]''.  We expect a consistent model to predict the same entity. Notice that the consistency measure does not require the answers to be factually correct. While correctness is also an important property for KBs, we view it as separate objective and measure them independently. 

% If the model predicts the correct $o_j^i$ as the most probable completion, we take that as evidence for the storing of the factual knowledge $d_j^i$ in the model. 
% In this case, a model that can perform adequate inference over the syntactic and lexical alternations between $p_j^i$ and $p_k^i$ is expected to also correctly predict the object from the alternative patterns $p_k^i$.

\paragraph{Restricted Candidate Sets}
Ideally, we would focus on the top-1 prediction that the PLM produces in order to compare between paraphrases. However, since these models were not trained for the purpose of serving as KBs, but as LMs, words outside of the inspected entities are often possible (e.g. the object in ``\subj{} was originally aired on \obj{}'' can also be replaced with `tv', to make a proper English sentence).
Therefore, we restrict the vocabulary produced by the PLMs to a candidate set, that is the set of possible gold objects for each relation, as was also suggested in previous work \cite{Xiong2020Pretrained, nora@@}.

Note that this procedure is a relaxation of the general problem, especially in the context of KBs, however, low consistency results in this setup are even more alarming.
