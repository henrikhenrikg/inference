@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{ijcai2020-537,
  title     = {Transformers as Soft Reasoners over Language},
  author    = {Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {3882--3890},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/537},
  url       = {https://doi.org/10.24963/ijcai.2020/537},
}

@inproceedings{Bosselut2019COMETCT,
  title={COMET: Commonsense Transformers for Automatic Knowledge Graph Construction},
  author={Antoine Bosselut and Hannah Rashkin and Maarten Sap and Chaitanya Malaviya and Asli Ã‡elikyilmaz and Yejin Choi},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2019}
}

@misc{heinzerling2020language,
      title={Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries}, 
      author={Benjamin Heinzerling and Kentaro Inui},
      year={2020},
      eprint={2008.09036},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{kassner-etal-2020-pretrained,
    title = "Are Pretrained Language Models Symbolic Reasoners over Knowledge?",
    author = {Kassner, Nora  and
      Krojer, Benno  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Proceedings of the 24th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.conll-1.45",
    pages = "552--564",
    abstract = "How can pretrained language models (PLMs) learn factual knowledge from the training set? We investigate the two most important mechanisms: reasoning and memorization. Prior work has attempted to quantify the number of facts PLMs learn, but we present, using synthetic data, the first study that investigates the causal relation between facts present in training and facts learned by the PLM. For reasoning, we show that PLMs seem to learn to apply some symbolic reasoning rules correctly but struggle with others, including two-hop reasoning. Further analysis suggests that even the application of learned reasoning rules is flawed. For memorization, we identify schema conformity (facts systematically supported by other facts) and frequency as key factors for its success.",
}

@inproceedings{lama,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.",
}


@inproceedings{yanaka-etal-2020-neural,
    title = "Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?",
    author = "Yanaka, Hitomi  and
      Mineshima, Koji  and
      Bekki, Daisuke  and
      Inui, Kentaro",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.543",
    doi = "10.18653/v1/2020.acl-main.543",
    pages = "6105--6117",
    abstract = "Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret lexical and logical phenomena on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set.",
}

@inproceedings{goodwin-etal-2020-probing,
    title = "Probing Linguistic Systematicity",
    author = "Goodwin, Emily  and
      Sinha, Koustuv  and
      O{'}Donnell, Timothy J.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.177",
    doi = "10.18653/v1/2020.acl-main.177",
    pages = "1958--1969",
    abstract = "Recently, there has been much interest in the question of whether deep natural language understanding (NLU) models exhibit systematicity, generalizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models do not learn systematically. We examine the notion of systematicity from a linguistic perspective, defining a set of probing tasks and a set of metrics to measure systematic behaviour. We also identify ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we perform a series of experiments in the setting of natural language inference (NLI). We provide evidence that current state-of-the-art NLU systems do not generalize systematically, despite overall high performance.",
}

@inproceedings{kassner-schutze-2020-negated,
    title = "Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly",
    author = {Kassner, Nora  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.698",
    doi = "10.18653/v1/2020.acl-main.698",
    pages = "7811--7818",
    abstract = "Building on Petroni et al. 2019, we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated ({`}{`}Birds cannot [MASK]{''}) and non-negated ({`}{`}Birds can [MASK]{''}) cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add {``}misprimes{''} to cloze questions ({`}{`}Talk? Birds can [MASK]{''}). We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.",
}

@article{ettinger-2020-bert,
    title = "What {BERT} Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models",
    author = "Ettinger, Allyson",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.tacl-1.3",
    doi = "10.1162/tacl_a_00298",
    pages = "34--48",
    abstract = "Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction{---} and, in particular, it shows clear insensitivity to the contextual impacts of negation.",
}

@inproceedings{schmitt-schutze-2019-sherliic,
    title = "{S}her{LI}i{C}: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference",
    author = {Schmitt, Martin  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1086",
    doi = "10.18653/v1/P19-1086",
    pages = "902--914",
    abstract = "We present SherLIiC, a testbed for lexical inference in context (LIiC), consisting of 3985 manually annotated inference rule candidates (InfCands), accompanied by (i) {\textasciitilde}960k unlabeled InfCands, and (ii) {\textasciitilde}190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09. Each InfCand consists of one of these relations, expressed as a lemmatized dependency path, and two argument placeholders, each linked to one or more Freebase types. Due to our candidate selection process based on strong distributional evidence, SherLIiC is much harder than existing testbeds because distributional evidence is of little utility in the classification of InfCands. We also show that, due to its construction, many of SherLIiC{'}s correct InfCands are novel and missing from existing rule bases. We evaluate a large number of strong baselines on SherLIiC, ranging from semantic vector space models to state of the art neural models of natural language inference (NLI). We show that SherLIiC poses a tough challenge to existing NLI systems.",
}


@article{talmor2019olmpics,
author = {Talmor, Alon and Elazar, Yanai and Goldberg, Yoav and Berant, Jonathan},
title = {oLMpics-On What Language Model Pre-training Captures},
journal = {Transactions of the Association for Computational Linguistics},
volume = {8},
number = {},
pages = {743-758},
year = {2020},
doi = {10.1162/tacl\_a\_00342},
URL = { 
        https://doi.org/10.1162/tacl_a_00342
},
eprint = { 
        https://doi.org/10.1162/tacl_a_00342
}
}

@article{yoav-syntax,
  title={Assessing BERT's syntactic abilities},
  author={Goldberg, Yoav},
  journal={arXiv preprint arXiv:1901.05287},
  year={2019}
}

@inproceedings{dagan-rte,
  title={The PASCAL recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  pages={177--190},
  year={2005},
  organization={Springer}
}

@inproceedings{structural-probe,
  author    = {John Hewitt and
               Christopher D. Manning},
  title     = {A Structural Probe for Finding Syntax in Word Representations},
  booktitle = {Proceedings of the Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT}},
  pages     = {4129--4138},
  year      = {2019},
  url       = {https://aclweb.org/anthology/papers/N/N19/N19-1419/},
  timestamp = {Fri, 07 Jun 2019 14:36:16 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/naacl/HewittM19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Bender2020ClimbingTN,
  title={Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data},
  author={Emily M. Bender and Alexander Koller},
  booktitle={ACL},
  year={2020}
}

@inproceedings{zhou2020evaluating,
  title={Evaluating Commonsense in Pre-Trained Language Models.},
  author={Zhou, Xuhui and Zhang, Yue and Cui, Leyang and Huang, Dandan},
  booktitle={AAAI},
  pages={9733--9740},
  year={2020}
}

@inproceedings{berant2011global,
  title={Global learning of typed entailment rules},
  author={Berant, Jonathan and Dagan, Ido and Goldberger, Jacob},
  booktitle={Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  pages={610--619},
  year={2011}
}

@phdthesis{berant2012global,
  title={Global Learning of Textual Entailment Graphs},
  author={Berant, Jonathan},
  year={2012},
  school={Tel Aviv University}
}

@article{javad2018learning,
  title={Learning typed entailment graphs with global soft constraints},
  author={Javad Hosseini, Mohammad and Chambers, Nathanael and Reddy, Siva and Holt, Xavier R and Cohen, Shay B and Johnson, Mark and Steedman, Mark},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={703--717},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{hosseini2019duality,
  title={Duality of Link Prediction and Entailment Graph Induction},
  author={Hosseini, Mohammad Javad and Cohen, Shay B and Johnson, Mark and Steedman, Mark},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4736--4746},
  year={2019}
}

@InProceedings{mnli,
  author = "Williams, Adina
            and Nangia, Nikita
            and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for 
           Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)",
  year = "2018",
  publisher = "Association for Computational Linguistics",
  pages = "1112--1122",
  location = "New Orleans, Louisiana",
  url = "http://aclweb.org/anthology/N18-1101"
}

@inproceedings{trex,
  title={T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples},
  author={Elsahar, Hady and Vougiouklis, Pavlos and Remaci, Arslen and Gravier, Christophe and Hare, Jonathon and Laforest, Frederique and Simperl, Elena},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{snli,
	Author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},
	Booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	Publisher = {Association for Computational Linguistics},
	Title = {A large annotated corpus for learning natural language inference},
	Year = {2015}
}

@inproceedings{schmitt2019sherliic,
  title={SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference},
  author={Schmitt, Martin and Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={902--914},
  year={2019}
}

@inproceedings{spike,
    title = "Syntactic Search by Example",
    author = "Shlain, Micah  and
      Taub-Tabib, Hillel  and
      Sadde, Shoval  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-demos.3",
    doi = "10.18653/v1/2020.acl-demos.3",
    pages = "17--23",
    abstract = "We present a system that allows a user to search a large linguistically annotated corpus using syntactic patterns over dependency graphs. In contrast to previous attempts to this effect, we introduce a light-weight query language that does not require the user to know the details of the underlying syntactic representations, and instead to query the corpus by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to efficient linguistic graph-indexing and retrieval engine. This allows for rapid exploration, development and refinement of syntax-based queries. We demonstrate the system using queries over two corpora: the English wikipedia, and a collection of English pubmed abstracts. A demo of the wikipedia system is available at https://allenai.github.io/spike/ .",
}

@inproceedings{bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{albert,
  title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{mccoy2019right,
  title={Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
  author={McCoy, Tom and Pavlick, Ellie and Linzen, Tal},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3428--3448},
  year={2019}
}

@inproceedings{consistent-qa,
    title = "Logic-Guided Data Augmentation and Regularization for Consistent Question Answering",
    author = "Asai, Akari  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.499",
    doi = "10.18653/v1/2020.acl-main.499",
    pages = "5642--5650",
}

@article{andersen2001easy,
  title={Easy cases of probabilistic satisfiability},
  author={Andersen, Kim Allan and Pretolani, Daniele},
  journal={Annals of Mathematics and Artificial Intelligence},
  volume={33},
  number={1},
  pages={69--91},
  year={2001},
  publisher={Springer}
}

@incollection{hansen2000probabilistic,
  title={Probabilistic satisfiability},
  author={Hansen, Pierre and Jaumard, Brigitte},
  booktitle={Handbook of Defeasible Reasoning and Uncertainty Management Systems},
  pages={321--367},
  year={2000},
  publisher={Springer}
}

@inproceedings{Thimm:2009d,
	Author = {Matthias Thimm},
	Booktitle = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI'09)},
	Editor = {Jeff Bilmes and Andrew Ng},
	Month = {June},
	Pages = {530--537},
	Location = {Montreal, Canada},
	Publisher = {AUAI Press},
	Title = {{Measuring Inconsistency in Probabilistic Knowledge Bases}},
	Year = {2009}
}

@article{Thimm:2013,
	Author = {Matthias Thimm},
	Journal = {Artificial Intelligence},
	Month = {April},
	Pages = {1--24},
	Title = {Inconsistency Measures for Probabilistic Logics},
	Volume = {197},
	Year = {2013}
}

@article{muino2011measuring,
  title={Measuring and repairing inconsistency in probabilistic knowledge bases},
  author={Mui{\~n}o, David Picado},
  journal={International Journal of Approximate Reasoning},
  volume={52},
  number={6},
  pages={828--840},
  year={2011},
  publisher={Elsevier}
}

@inproceedings{
petroni2020how,
title={How Context Affects Language Models' Factual Predictions},
author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},
booktitle={Automated Knowledge Base Construction},
year={2020},
url={https://openreview.net/forum?id=025X0zPfn}
}