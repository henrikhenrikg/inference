\section{Conclusions}
\label{sec:conclusions}

In this work, we study the consistency of PLMs with regard to their ability to extract knowledge.
We build a high-quality resource named \resource{}, that contains 328, high-quality patterns for thirty-eight relations.
Using \resource{}, we measure consistency in multiple PLMs, including BERT, RoBERTa, and ALBERT, and show that although the two latter are superior in other tasks over BERT, they fall short in terms of consistency. However, overall the consistency ability of these models is low.
We release \resource{} along with data tuples from T-REx as a new benchmark, to track models' consistency to knowledge.
Finally, we propose a new simple method to improve PLMs' consistency, by continuing the pretraining with a novel loss. We show this method to be effective and to improve both the consistency of models as well as their ability to extract the correct facts.
