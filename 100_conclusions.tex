\section{Conclusions}
\label{sec:conclusions}

In this work, we study the consistency of PLMs with regard to their ability to extract knowledge.
We build a high-quality resource named \resource{}, that contain @@ patterns for 40 different relations.
Using \resource{}, we measure consistency in multiple PLMs, including BERT, RoBERTa, and ALBERT, and show that although the two latter are superior in other tasks over BERT, they fall short in terms of consistency. However, overall the consistency ability of these models is low.
We release \resource{} along with data tuples from \cite{trex} as a new benchmark, to track the consistency of models to knowledge.
Finally, we propose a new and simple method to improve the consistency of PLMs, by continuing the pretraining step with a novel loss. We show this method to be effective and improves both the consistency of models as well as their ability to extract the correct facts.
